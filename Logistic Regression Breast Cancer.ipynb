{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression Breast Cancer.ipynb","provenance":[],"authorship_tag":"ABX9TyP4XqQZgVVMN2sbjskdQ99w"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0B_BKUFlSRg","executionInfo":{"status":"ok","timestamp":1608638510059,"user_tz":-180,"elapsed":3834,"user":{"displayName":"Trevor Mwaniki","photoUrl":"","userId":"11048947077256251111"}},"outputId":"71050989-803a-4abc-c608-90c264812c1a"},"source":["!pip install -U scikit-learn\r\n","%tensorflow_version 2.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n","Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2jb6jSfD1kDC"},"source":["From features generate malignant or begnin percentages using logistic regression for the breast cancer dataset."]},{"cell_type":"markdown","metadata":{"id":"oQtp0lEmsnpn"},"source":[" Re-install scikit-learn. Default version is 0.22, upgrading to 0.23.2. Reason: new parameter made available to import the dataset as a pandas DataFrame."]},{"cell_type":"markdown","metadata":{"id":"FKLmQeEbsbSt"},"source":[""]},{"cell_type":"code","metadata":{"id":"B14PF0htiKaQ"},"source":["import pandas as pd\r\n","import sklearn\r\n","import tensorflow as tf\r\n","import tensorflow.compat.v2.feature_column as fc \r\n","from sklearn.datasets import load_breast_cancer\r\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ibBHaqZOtWwh"},"source":[" Import required python libraries."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpleJLKyizEM","executionInfo":{"status":"ok","timestamp":1608644319023,"user_tz":-180,"elapsed":733,"user":{"displayName":"Trevor Mwaniki","photoUrl":"","userId":"11048947077256251111"}},"outputId":"08f78435-ebf7-4399-cc33-e0dc688f5656"},"source":["dataset = load_breast_cancer(as_frame=True)\n","x_train, x_eval , y_train, y_eval = train_test_split(dataset.data, dataset.target, test_size = 0.3, random_state = 0)\n"," \n","print('x, y | {}, {}'.format(x_train.shape, y_train.shape))\n","print(dataset.target.value_counts())\n","print('212 - Malignant, 357 - Benign')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x, y | (398, 30), (398,)\n","1    357\n","0    212\n","Name: target, dtype: int64\n","212 - Malignant, 357 - Benign\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oE8bb1p4tffp"},"source":["Load the breast cancer dataset as a pandas Dataframe. After loading, split the dataset into train and evaluation datasets in the ratio 0.7:0.3.\n","Additionally check the x_train dataset shape to ensure that the 1st dimension is similar to the 1st dimension of the evaluation dataset.\n"," \n","The dataset has two target variables Malignant,Benign labelled as 1 and 0 respectively. We are interested in the target variable because we will check how well the model does in percentage in predicting the target variables."]},{"cell_type":"markdown","metadata":{"id":"h80OC82EslMc"},"source":[""]},{"cell_type":"code","metadata":{"id":"XJnePI_XuI9f"},"source":["FEATURE_COLUMNS = []\r\n","NUMERICAL_COLUMNS = dataset.feature_names\r\n","for n in NUMERICAL_COLUMNS:\r\n","  FEATURE_COLUMNS.append(tf.feature_column.numeric_column(n, dtype = tf.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHxzaGiZuUeL"},"source":[" The x_train and x_eval dataset contain 30 columns that are being translated to feature columns which describe to the estimator model how each feature should be interpreted. In this case a tf.feature_column.numerical_column is used since the dataset's columns' values are numbers. Tensorflow additionally supports categorical data. However, in this case it will not be put into use."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNAMRv8kwSJe","executionInfo":{"status":"ok","timestamp":1608638524788,"user_tz":-180,"elapsed":18541,"user":{"displayName":"Trevor Mwaniki","photoUrl":"","userId":"11048947077256251111"}},"outputId":"a442659a-257c-4181-e59b-ca1583a2b3b2"},"source":["#Input function required by tf.estimator.LinearClassifier\n","def input_fn(train_data, labels, epochs = 40, shuffle = True, batch_size = 20):\n","  ds = tf.data.Dataset.from_tensor_slices((dict(train_data), labels))\n","  if shuffle:\n","    ds = ds.shuffle(1159)\n","  ds = ds.batch(batch_size).repeat(epochs)\n","  return ds\n"," \n","mean_cross = tf.feature_column.crossed_column(['mean compactness', 'mean area'], hash_bucket_size= 30)\n","smoothness_radius = tf.feature_column.crossed_column(['mean radius', 'mean smoothness'], hash_bucket_size=30)\n","concativity_x_points = tf.feature_column.crossed_column(['mean concavity', 'mean concave points'], hash_bucket_size=30)\n","crossed_columns = [mean_cross, smoothness_radius]\n","linear_estimator = tf.estimator.LinearClassifier(feature_columns=FEATURE_COLUMNS + crossed_columns)\n","linear_estimator.train(input_fn= lambda: input_fn(x_train, y_train))\n","result = linear_estimator.evaluate(input_fn= lambda: input_fn(x_eval, y_eval, shuffle=False))\n","predictions = list(linear_estimator.predict(input_fn= lambda: input_fn(x_eval, y_eval, shuffle=False)))\n","print('Model accuracy: {}'.format(result['accuracy']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7ylnd1yh\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp7ylnd1yh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:134: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n","INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp7ylnd1yh/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n","INFO:tensorflow:loss = 0.6931472, step = 0\n","INFO:tensorflow:global_step/sec: 258.73\n","INFO:tensorflow:loss = 1.2733376, step = 100 (0.392 sec)\n","WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 106 vs previous value: 106. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n","INFO:tensorflow:global_step/sec: 577.857\n","INFO:tensorflow:loss = 0.39867023, step = 200 (0.172 sec)\n","WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 213 vs previous value: 213. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n","INFO:tensorflow:global_step/sec: 548.36\n","INFO:tensorflow:loss = 0.6502207, step = 300 (0.181 sec)\n","WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 368 vs previous value: 368. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n","WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 372 vs previous value: 372. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n","INFO:tensorflow:global_step/sec: 564.089\n","INFO:tensorflow:loss = 0.342014, step = 400 (0.175 sec)\n","INFO:tensorflow:global_step/sec: 638.987\n","INFO:tensorflow:loss = 0.6365889, step = 500 (0.157 sec)\n","INFO:tensorflow:global_step/sec: 629.827\n","INFO:tensorflow:loss = 0.3681311, step = 600 (0.159 sec)\n","INFO:tensorflow:global_step/sec: 638.999\n","INFO:tensorflow:loss = 0.99296, step = 700 (0.160 sec)\n","INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 800...\n","INFO:tensorflow:Saving checkpoints for 800 into /tmp/tmp7ylnd1yh/model.ckpt.\n","INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 800...\n","INFO:tensorflow:Loss for final step: 3.4935415.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-12-22T12:02:00Z\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmp7ylnd1yh/model.ckpt-800\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Inference Time : 1.35571s\n","INFO:tensorflow:Finished evaluation at 2020-12-22-12:02:01\n","INFO:tensorflow:Saving dict for global step 800: accuracy = 0.94152045, accuracy_baseline = 0.6315789, auc = 0.9642858, auc_precision_recall = 0.96096385, average_loss = 0.34495217, global_step = 800, label/mean = 0.6315789, loss = 0.3277107, precision = 0.92241377, prediction/mean = 0.67963046, recall = 0.9907407\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: /tmp/tmp7ylnd1yh/model.ckpt-800\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmp7ylnd1yh/model.ckpt-800\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","Model accuracy: 0.9415204524993896\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vnKTyxd0wf3Y"},"source":[" This section an input function which returns a tf.data.Dataset object (possibly containing large dataset) This objects pipes the dataset to the model through steaming due to limited system resources in batches. If the model is training we shuffle the data and batch it in 20. \n","Afterwards, a crossed column between different features is made to increase the accuracy of the model. Using a single column, the model will assess how this column contributes to the output. However, crossing columns takes into account how two columns together contribute to the output. For example how does mean concavity and mean concavity points contribute to the output, associated weights have to be generated for this. We noted that crossing columns do not always increase the model accuracy. The crossed columns made above increased the accuracy from 91 to 94 percent.\n"," \n","Lastly,we create and train a LinearClassifier model. After training the model, we evaluate it and from the results of the evaluation , accuracy and loss can be obtained. From evaluation we use the same evaluation dataset to make a prediction."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pKOmVsqIHrQ","executionInfo":{"status":"ok","timestamp":1608646092956,"user_tz":-180,"elapsed":1593,"user":{"displayName":"Trevor Mwaniki","photoUrl":"","userId":"11048947077256251111"}},"outputId":"c04f5d4e-efd3-45d9-f470-a2a53d77daad"},"source":["location_index = 1\n","print(dataset.data.loc[location_index]) #should locate data from the x_eval dataset\n","print('Label assigned: {}'.format(dataset.target.loc[location_index]))\n","print('Model prediction: {}'.format(predictions[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean radius                  20.570000\n","mean texture                 17.770000\n","mean perimeter              132.900000\n","mean area                  1326.000000\n","mean smoothness               0.084740\n","mean compactness              0.078640\n","mean concavity                0.086900\n","mean concave points           0.070170\n","mean symmetry                 0.181200\n","mean fractal dimension        0.056670\n","radius error                  0.543500\n","texture error                 0.733900\n","perimeter error               3.398000\n","area error                   74.080000\n","smoothness error              0.005225\n","compactness error             0.013080\n","concavity error               0.018600\n","concave points error          0.013400\n","symmetry error                0.013890\n","fractal dimension error       0.003532\n","worst radius                 24.990000\n","worst texture                23.410000\n","worst perimeter             158.800000\n","worst area                 1956.000000\n","worst smoothness              0.123800\n","worst compactness             0.186600\n","worst concavity               0.241600\n","worst concave points          0.186000\n","worst symmetry                0.275000\n","worst fractal dimension       0.089020\n","Name: 1, dtype: float64\n","Label assigned: 0\n","Model prediction: {'logits': array([-6.0231524], dtype=float32), 'logistic': array([0.00241616], dtype=float32), 'probabilities': array([0.99758387, 0.00241617], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object), 'all_class_ids': array([0, 1], dtype=int32), 'all_classes': array([b'0', b'1'], dtype=object)}\n"],"name":"stdout"}]}]}